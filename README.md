# ASR+Diarization Worker (GCP / Cloud Run GPU)

Bu depo, dublaj pipeline'Ä±nÄ±n **ASR (WhisperX)** + **Diarization (pyannote / NeMo MSDD / GCP STT)**
aÅŸamalarÄ±nÄ± Ã§alÄ±ÅŸtÄ±ran **plugin mimarili** bir AI "worker" servisidir.
- Artefact standartlarÄ±: `asr_segments.jsonl`, `diar_segments.jsonl`, `speaker_profiles.json` (opsiyonel), `edl.jsonl`
- Ã‡alÄ±ÅŸtÄ±rma: CLI veya Cloud Run Job
- GiriÅŸ: GCS URI (`gs://...`) veya yerel dosya
- Ã‡Ä±kÄ±ÅŸ: GCS prefix veya yerel klasÃ¶r

> Not: Bu repo **AI worker** katmanÄ±dÄ±r. API ve Web UI ayrÄ± projelerdir.



## HÄ±zlÄ± BaÅŸlangÄ±Ã§ (Yerel / GPU)

```bash
source $(poetry env info --path)/bin/activate
# Shell plugin'ini yÃ¼kle
poetry self add poetry-plugin-shell

# ArtÄ±k shell komutunu kullanabilirsiniz
poetry shell
export HF_TOKEN="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"
export GOOGLE_APPLICATION_CREDENTIALS="$(pwd)/voiceprocess-58fbc-8e5f0264cdc0.json"

## Ã‡Ä±ktÄ±lar
(dublaj-pipeline-py3.10) videodubb_voiceprocess_io@instance-20250904-153243:~/PycharmProjects/dublaj/pyannote$ poetry run python app-full.py --audio ../input_6.wav   --out out.jsonl   --hf-token "$HF_TOKEN"  --do-mix 
usage: app-full.py [-h] --audio AUDIO --out OUT [--hf-token HF_TOKEN] [--asr-model ASR_MODEL] [--asr-device ASR_DEVICE] [--asr-compute-type ASR_COMPUTE_TYPE] [--vad-onset VAD_ONSET]
                   [--vad-offset VAD_OFFSET] [--vad-min-on VAD_MIN_ON] [--vad-min-off VAD_MIN_OFF] [--osd-onset OSD_ONSET] [--osd-offset OSD_OFFSET] [--osd-min-on OSD_MIN_ON]
                   [--osd-min-off OSD_MIN_OFF] [--require-vad] [--vad-coverage VAD_COVERAGE] [--min-speakers MIN_SPEAKERS] [--max-speakers MAX_SPEAKERS] [--output-dir OUTPUT_DIR]
app-full.py: error: unrecognized arguments: --do-mix
(dublaj-pipeline-py3.10) videodubb_voiceprocess_io@instance-20250904-153243:~/PycharmProjects/dublaj/pyannote$ poetry run python app-full.py --audio ../input_6.wav   --out out.jsonl   --hf-token "$HF_TOKEN"  
ğŸµ Audio: ../input_6.wav
ğŸ“ Ã‡Ä±kÄ±ÅŸ: out.jsonl
ğŸ“ AdÄ±m Ã§Ä±ktÄ± dizini: .
ğŸ¤– ASR: large-v3 (device=auto, compute=auto)
============================================================
ğŸ“ ADIM 1: Voice Activity Detection (VAD)
ğŸ”§ VAD modeli yÃ¼kleniyor (pyannote/brouhaha)...
Lightning automatically upgraded your loaded checkpoint from v1.6.5 to v2.5.5. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--brouhaha/snapshots/c93c9b537732dd50c28c0366c73f560c3a7aeb02/pytorch_model.bin`
Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.
Model was trained with torch 1.12.1+cu102, yours is 2.3.1+cu121. Bad things might happen unless you revert torch to 1.x.
âš™ï¸  VAD parametreleri: onset=0.0, offset=0.0, min_on=0.0, min_off=0.0
âœ… VAD modeli hazÄ±r
ğŸ” VAD analizi yapÄ±lÄ±yor...
âœ… VAD tamam: 1 segment, toplam 137.65s
ğŸ’¾ step1_vad Ã§Ä±ktÄ±sÄ± kaydedildi: ./step1_vad.json

ğŸ“ ADIM 2: Overlapped Speech Detection (OSD)
ğŸ”§ OSD modeli yÃ¼kleniyor (pyannote/segmentation-3.1)...
âš™ï¸  OSD parametreleri: onset=0.0, offset=0.0, min_on=0.1, min_off=0.1
âœ… OSD modeli hazÄ±r
ğŸ” OSD analizi yapÄ±lÄ±yor...
âœ… OSD tamam: 23 segment, toplam 44.58s
ğŸ’¾ step2_osd Ã§Ä±ktÄ±sÄ± kaydedildi: ./step2_osd.json

ğŸ“ ADIM 3: Speaker Diarization
ğŸ”§ Diarization modeli yÃ¼kleniyor (pyannote/speaker-diarization-3.1)...
âœ… Diarization modeli hazÄ±r
ğŸ” Diarization analizi yapÄ±lÄ±yor...
/home/videodubb_voiceprocess_io/.cache/pypoetry/virtualenvs/dublaj-pipeline-KrFI56mV-py3.10/lib/python3.10/site-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1807.)
  std = sequences.std(dim=-1, correction=1)




```
out/
  asr_segments.jsonl
  diar_segments.jsonl
  speaker_profiles.json   # opsiyonel
  asr_words_speaker.jsonl # kelime->konuÅŸmacÄ± eÅŸlemesi
  edl.jsonl               # cut-list
```

## Docker (Cloud Run GPU)
```bash
gcloud builds submit --tag gcr.io/$PROJECT/asr-diarize-worker:latest
gcloud run deploy asr-diarize-worker --image gcr.io/$PROJECT/asr-diarize-worker:latest   --region=us-central1 --cpu=4 --memory=16Gi --gpu=1 --gpu-type=nvidia-l4   --no-allow-unauthenticated --max-instances=5
```

## Lisans / Modeller
- `pyannote.audio` iÃ§in HF token ve model lisans koÅŸullarÄ±na uyunuz.
- NeMo MSDD modelleri NVIDIA lisansÄ± ile sunulur.
- Google STT kullanÄ±mÄ± Ã¼cretlidir.

## YapÄ±
- `dubbing_ai/` ana paket
- `dubbing_ai/diarizer/` diarization plugin'leri
- `dubbing_ai/transcriber/` ASR (WhisperX) eklentisi
- `dubbing_ai/align/` kelimeâ†’konuÅŸmacÄ± eÅŸlemesi ve EDL
- `dubbing_ai/utils/` GCS IO, audio yardÄ±mcÄ±larÄ±
- `configs/` Ã¶rnek NeMo konfig ve Cloud Run Job env Ã¶rneÄŸi

Ãœretimde, FFmpeg/yt-dlp/lip-sync wrapper'larÄ±nÄ±zÄ± API katmanÄ±ndan bu worker'a parametre ile baÄŸlayabilirsiniz.
