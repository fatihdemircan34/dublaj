#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
=============================================================================
SES DOSYASI DÄ°ARÄ°ZASYON VE TRANSKRÄ°PSÄ°YON SÄ°STEMÄ°
=============================================================================

Bu program ÅŸunlarÄ± yapar:
1. Ses dosyasÄ±nÄ± (MP4/MP3/WAV) alÄ±r
2. Kimin ne zaman konuÅŸtuÄŸunu tespit eder (diarizasyon)
3. KonuÅŸulanlarÄ± metne dÃ¶ker (transkripsiyon)
4. Her kelimeyi doÄŸru konuÅŸmacÄ±ya atar
5. AnlamlÄ± cÃ¼mle segmentleri oluÅŸturur

KullanÄ±lan teknolojiler:
- PyAnnote: KonuÅŸmacÄ± tespiti iÃ§in
- Whisper: KonuÅŸma tanÄ±ma iÃ§in
- FFmpeg: Ses formatÄ± dÃ¶nÃ¼ÅŸÃ¼mÃ¼ iÃ§in
=============================================================================
"""

import httpx
import sys
import json
import tempfile
import argparse
import subprocess
import logging
from typing import List, Dict, Optional, Tuple
from collections import defaultdict
from bisect import insort
from datetime import datetime

import anthropic
import json
import os

import numpy as np
from pyannote.audio import Model, Pipeline
from pyannote.audio.pipelines import VoiceActivityDetection, OverlappedSpeechDetection
from pyannote.core import Segment, Timeline, Annotation
from faster_whisper import WhisperModel
import warnings

warnings.filterwarnings("ignore", message=".*torchaudio.*deprecated.*")

# ========================= DEBUG LOGGER KURULUMU =========================

class ColoredFormatter(logging.Formatter):
    """Renkli log Ã§Ä±ktÄ±larÄ± iÃ§in Ã¶zel formatter"""

    COLORS = {
        'DEBUG': '\033[36m',     # Cyan
        'INFO': '\033[32m',      # Green
        'WARNING': '\033[33m',   # Yellow
        'ERROR': '\033[31m',     # Red
        'CRITICAL': '\033[35m',  # Magenta
    }
    RESET = '\033[0m'
    BOLD = '\033[1m'

    def format(self, record):
        log_color = self.COLORS.get(record.levelname, self.RESET)
        record.levelname = f"{log_color}{self.BOLD}[{record.levelname}]{self.RESET}"
        record.msg = f"{log_color}{record.msg}{self.RESET}"
        return super().format(record)

def setup_logger(debug_level: str = "INFO", log_file: Optional[str] = None):
    """
    Debug logger'Ä± yapÄ±landÄ±r

    debug_level: DEBUG, INFO, WARNING, ERROR, CRITICAL
    log_file: Log dosyasÄ± yolu (opsiyonel)
    """
    logger = logging.getLogger('diarization')
    logger.setLevel(getattr(logging, debug_level.upper()))

    # Console handler (renkli)
    console_handler = logging.StreamHandler()
    console_formatter = ColoredFormatter(
        '%(asctime)s %(levelname)s %(funcName)s:%(lineno)d - %(message)s',
        datefmt='%H:%M:%S'
    )
    console_handler.setFormatter(console_formatter)
    logger.addHandler(console_handler)

    # File handler (opsiyonel)
    if log_file:
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s'
        )
        file_handler.setFormatter(file_formatter)
        logger.addHandler(file_handler)

    return logger

# Global logger
logger = logging.getLogger('diarization')

# ========================= YARDIMCI FONKSÄ°YONLAR =========================

def format_time(seconds: float) -> str:
    """Saniyeyi okunabilir formata Ã§evir (MM:SS.mmm)"""
    minutes = int(seconds // 60)
    secs = seconds % 60
    return f"{minutes:02d}:{secs:06.3f}"

def round3(x: Optional[float]) -> Optional[float]:
    """SayÄ±yÄ± 3 ondalÄ±k basamaÄŸa yuvarla"""
    if x is None:
        return None
    result = round(x, 3)
    logger.debug(f"Yuvarlama: {x:.6f} â†’ {result:.3f}")
    return result

def log_segment(seg: Segment, label: str = "Segment"):
    """Segment bilgilerini logla"""
    logger.debug(f"{label}: [{format_time(seg.start)} - {format_time(seg.end)}] "
                 f"(SÃ¼re: {seg.duration:.3f}s)")

def log_timeline(timeline: Timeline, label: str = "Timeline"):
    """Timeline bilgilerini logla"""
    total_duration = sum(s.duration for s in timeline)
    logger.info(f"{label}: {len(timeline)} segment, "
                f"Toplam sÃ¼re: {total_duration:.2f}s")

    if logger.level <= logging.DEBUG:
        for i, seg in enumerate(timeline[:5]):  # Ä°lk 5 segmenti gÃ¶ster
            log_segment(seg, f"  Segment {i+1}")
        if len(timeline) > 5:
            logger.debug(f"  ... ve {len(timeline)-5} segment daha")

# ========================= SES DÃ–NÃœÅTÃœRME =========================

def ffmpeg_to_wav_mono16k(src_path: str) -> str:
    """
    Ses dosyasÄ±nÄ± iÅŸlenebilir formata Ã§evir

    NEDEN GEREKLÄ°?
    - PyAnnote ve Whisper modelleri 16kHz mono WAV formatÄ±nda Ã§alÄ±ÅŸÄ±r
    - MP4/MP3 gibi formatlar direkt iÅŸlenemez
    - Stereo ses mono'ya Ã§evrilmeli (tek kanal)

    Args:
        src_path: Kaynak ses dosyasÄ± (MP4, MP3, WAV, vb.)

    Returns:
        DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ WAV dosyasÄ±nÄ±n yolu
    """
    logger.info(f"Ses dosyasÄ± dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor: {src_path}")

    # Dosya kontrolÃ¼
    if not os.path.exists(src_path):
        logger.error(f"Dosya bulunamadÄ±: {src_path}")
        raise FileNotFoundError(f"Girdi dosyasÄ± bulunamadÄ±: {src_path}")

    file_size = os.path.getsize(src_path) / (1024 * 1024)  # MB
    logger.info(f"Dosya boyutu: {file_size:.2f} MB")

    # GeÃ§ici WAV dosyasÄ± oluÅŸtur
    tmp_wav = tempfile.mktemp(suffix=".wav")
    logger.debug(f"GeÃ§ici dosya: {tmp_wav}")

    # FFmpeg komutu
    cmd = [
        "ffmpeg", "-y",           # Evet, Ã¼zerine yaz
        "-i", src_path,           # Girdi dosyasÄ±
        "-ac", "1",               # Audio channels: 1 (mono)
        "-ar", "16000",           # Audio rate: 16kHz
        "-vn",                    # Video no (videoyu dahil etme)
        "-f", "wav",              # Format: WAV
        tmp_wav                   # Ã‡Ä±ktÄ± dosyasÄ±
    ]

    logger.debug(f"FFmpeg komutu: {' '.join(cmd)}")

    try:
        # FFmpeg'i Ã§alÄ±ÅŸtÄ±r
        result = subprocess.run(
            cmd,
            check=True,
            capture_output=True,
            text=True
        )

        # DÃ¶nÃ¼ÅŸtÃ¼rÃ¼len dosya boyutu
        wav_size = os.path.getsize(tmp_wav) / (1024 * 1024)
        logger.info(f"âœ“ DÃ¶nÃ¼ÅŸtÃ¼rme tamamlandÄ±. WAV boyutu: {wav_size:.2f} MB")

        # FFmpeg Ã§Ä±ktÄ±sÄ±nÄ± debug modunda gÃ¶ster
        if result.stderr and logger.level <= logging.DEBUG:
            logger.debug("FFmpeg Ã§Ä±ktÄ±sÄ±:")
            for line in result.stderr.split('\n')[:10]:
                if line.strip():
                    logger.debug(f"  {line}")

    except subprocess.CalledProcessError as e:
        logger.error(f"FFmpeg hatasÄ±: {e}")
        logger.error(f"Hata Ã§Ä±ktÄ±sÄ±: {e.stderr if hasattr(e, 'stderr') else 'N/A'}")
        raise RuntimeError(f"FFmpeg dÃ¶nÃ¼ÅŸtÃ¼rme hatasÄ±: {e}")

    return tmp_wav

# ========================= TIMELINE Ä°ÅLEMLERÄ° =========================

def timeline_to_dict(tl: Timeline) -> List[Dict]:
    """Timeline nesnesini JSON'a yazÄ±labilir formata Ã§evir"""
    result = []
    for seg in tl:
        result.append({
            "start": round3(seg.start),
            "end": round3(seg.end),
            "duration": round3(seg.duration)
        })

    logger.debug(f"Timeline â†’ Dict: {len(tl)} segment dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼")
    return result

def diarization_to_dict(di: Annotation) -> List[Dict]:
    """Diarization sonuÃ§larÄ±nÄ± JSON formatÄ±na Ã§evir"""
    result = []
    speaker_times = defaultdict(float)  # Her konuÅŸmacÄ±nÄ±n toplam sÃ¼resi

    for turn, _, label in di.itertracks(yield_label=True):
        result.append({
            "start": round3(turn.start),
            "end": round3(turn.end),
            "duration": round3(turn.duration),
            "speaker": label
        })
        speaker_times[label] += turn.duration

    # KonuÅŸmacÄ± istatistikleri
    logger.info(f"KonuÅŸmacÄ± istatistikleri:")
    for speaker, duration in sorted(speaker_times.items()):
        logger.info(f"  {speaker}: {duration:.1f}s ({duration/60:.1f} dakika)")

    return result

def timeline_coverage_ratio(timeline: Timeline, seg: Segment) -> float:
    """
    Bir segmentin timeline tarafÄ±ndan ne kadar kaplandÄ±ÄŸÄ±nÄ± hesapla

    KULLANIM AMACI:
    VAD (Voice Activity Detection) kontrolÃ¼ iÃ§in kullanÄ±lÄ±r.
    Bir kelimenin gerÃ§ekten konuÅŸma iÃ§inde mi yoksa sessizlikte mi
    olduÄŸunu anlamak iÃ§in.
    """
    if seg.duration <= 0:
        return 0.0

    covered = 0.0
    overlaps = []

    for t in timeline:
        intersection = t & seg  # KesiÅŸim
        if intersection is not None:
            covered += intersection.duration
            overlaps.append(intersection)

    ratio = min(1.0, covered / seg.duration)

    if logger.level <= logging.DEBUG and overlaps:
        logger.debug(f"Kapsama hesabÄ±: Segment [{format_time(seg.start)}-{format_time(seg.end)}]")
        logger.debug(f"  {len(overlaps)} kesiÅŸim, Kapsama: {ratio:.2%}")

    return ratio

def timeline_overlaps(timeline: Timeline, seg: Segment) -> bool:
    """Segment ile timeline'Ä±n kesiÅŸip kesiÅŸmediÄŸini kontrol et"""
    for t in timeline:
        if (t & seg) is not None:
            logger.debug(f"Ã‡akÄ±ÅŸma tespit edildi: [{format_time(seg.start)}-{format_time(seg.end)}]")
            return True
    return False

def intersect_timelines(t1: Timeline, t2: Timeline) -> Timeline:
    """
    Ä°ki timeline'Ä±n kesiÅŸimini bul

    KULLANIM AMACI:
    FarklÄ± algÄ±lama sistemlerinin (VAD, OSD, Diarization) sonuÃ§larÄ±nÄ±
    birleÅŸtirerek daha gÃ¼venilir Ã§akÄ±ÅŸma bÃ¶lgeleri bulmak iÃ§in.
    """
    logger.debug(f"Timeline kesiÅŸimi hesaplanÄ±yor: "
                 f"T1({len(t1)} seg) âˆ© T2({len(t2)} seg)")

    intersections = []
    for a in t1:
        for b in t2:
            ab = a & b
            if ab is not None and ab.duration > 0:
                intersections.append(ab)

    result = Timeline(intersections).support() if intersections else Timeline()
    logger.debug(f"KesiÅŸim sonucu: {len(result)} segment")

    return result

def build_overlap_from_diarization(diar: Annotation, min_count: int = 2) -> Timeline:
    """
    Diarization'dan Ã§akÄ±ÅŸan konuÅŸma bÃ¶lgelerini tespit et

    NASIL Ã‡ALIÅIR?
    1. TÃ¼m konuÅŸma baÅŸlangÄ±Ã§ ve bitiÅŸlerini topla
    2. Zaman Ã§izgisinde ilerle
    3. Her noktada kaÃ§ kiÅŸi konuÅŸuyor say
    4. 2+ kiÅŸi konuÅŸuyorsa = Ã§akÄ±ÅŸma

    Bu "sweep line algoritmasÄ±" olarak bilinir.
    """
    logger.info("Ã‡akÄ±ÅŸan konuÅŸma bÃ¶lgeleri tespit ediliyor...")

    # TÃ¼m zaman noktalarÄ±nÄ± topla
    # +1 = konuÅŸma baÅŸlÄ±yor, -1 = konuÅŸma bitiyor
    bounds = []
    for turn, _, label in diar.itertracks(yield_label=True):
        insort(bounds, (turn.start, +1))  # BaÅŸlangÄ±Ã§
        insort(bounds, (turn.end, -1))    # BitiÅŸ

    logger.debug(f"Toplam {len(bounds)} zaman noktasÄ± iÅŸlenecek")

    # Zaman Ã§izgisinde ilerleyerek Ã§akÄ±ÅŸmalarÄ± bul
    overlaps = []
    active_count = 0  # Åu anda konuÅŸan kiÅŸi sayÄ±sÄ±
    prev_time = None

    for time, delta in bounds:
        # EÄŸer 2+ kiÅŸi konuÅŸuyorsa, bu aralÄ±ÄŸÄ± Ã§akÄ±ÅŸma olarak kaydet
        if prev_time is not None and time > prev_time and active_count >= min_count:
            overlap_seg = Segment(prev_time, time)
            overlaps.append(overlap_seg)

            if logger.level <= logging.DEBUG:
                logger.debug(f"  Ã‡akÄ±ÅŸma: [{format_time(prev_time)}-{format_time(time)}] "
                             f"({active_count} konuÅŸmacÄ±)")

        active_count += delta
        prev_time = time

    result = Timeline(overlaps).support() if overlaps else Timeline()
    logger.info(f"âœ“ {len(result)} Ã§akÄ±ÅŸma bÃ¶lgesi bulundu")

    return result

# ========================= MODEL YÃœKLEYÄ°CÄ°LER =========================

def build_vad(hf_token: str, onset=0.5, offset=0.5,
              min_on=0.0, min_off=0.0):
    """
    Voice Activity Detection (VAD) - PyAnnote 3.1.1 Uyumlu
    """
    logger.info("VAD yapÄ±landÄ±rÄ±lÄ±yor (PyAnnote 3.1.1)...")

    try:
        from pyannote.audio import Model
        from pyannote.audio.pipelines import VoiceActivityDetection

        logger.info("Segmentation modeli yÃ¼kleniyor...")

        # PyAnnote 3.x model ismi
        model = Model.from_pretrained(
            "pyannote/segmentation-3.0",
            use_auth_token=hf_token
        )
        logger.info("âœ“ Segmentation modeli yÃ¼klendi")

        # VAD pipeline oluÅŸtur
        vad = VoiceActivityDetection(segmentation=model)

        # PyAnnote 3.x parametreleri - onset/offset YOK!
        HYPER_PARAMETERS = {
            "min_duration_on": min_on,    # onset yerine bu
            "min_duration_off": min_off,   # offset yerine bu
        }

        try:
            vad.instantiate(HYPER_PARAMETERS)
            logger.info("âœ“ VAD parametreleri ayarlandÄ±")
        except Exception as e:
            logger.warning(f"Parametreler uygulanamadÄ±: {e}")
            logger.info("VarsayÄ±lan parametrelerle devam ediliyor...")
            vad.instantiate({})  # BoÅŸ dict ile baÅŸlat

        logger.info("âœ“ VAD sistemi hazÄ±r")
        return vad

    except Exception as e:
        logger.error(f"VAD modeli yÃ¼klenemedi: {e}")
        logger.warning("Alternatif: Diarization tabanlÄ± VAD kullanÄ±lacak")

        class DiarizationBasedVAD:
            def __init__(self):
                self.is_fallback = True
                self.vad_timeline = None
                logger.info("DiarizationBasedVAD yedek sistemi aktif")

            def __call__(self, wav_path):
                logger.info("VAD bilgisi diarization'dan Ã§Ä±karÄ±lacak")
                from pyannote.core import Timeline
                return Timeline()

        return DiarizationBasedVAD()

def build_osd(hf_token: str, min_on=0.10, min_off=0.10) -> OverlappedSpeechDetection:
    """
    Overlapped Speech Detection (OSD) modeli oluÅŸtur

    OSD NEDÄ°R?
    Ä°ki veya daha fazla kiÅŸinin aynÄ± anda konuÅŸtuÄŸu bÃ¶lÃ¼mleri tespit eder.
    KesiÅŸen konuÅŸmalarÄ± bulmak kritik Ã§Ã¼nkÃ¼ bu bÃ¶lgelerde
    konuÅŸmacÄ± atamasÄ± zor ve hata payÄ± yÃ¼ksek.
    """
    logger.info("OSD (Ã‡akÄ±ÅŸan KonuÅŸma) modeli yÃ¼kleniyor...")
    logger.debug(f"Parametreler: min_on={min_on}, min_off={min_off}")

    try:
        seg_model = Model.from_pretrained(
            "pyannote/segmentation-3.0",
            use_auth_token=hf_token
        )
        logger.info("âœ“ OSD modeli yÃ¼klendi")

        osd = OverlappedSpeechDetection(segmentation=seg_model)
        osd.instantiate({
            "min_duration_on": min_on,
            "min_duration_off": min_off
        })

        return osd

    except Exception as e:
        logger.error(f"OSD modeli yÃ¼klenemedi: {e}")
        raise

def build_diarization(hf_token: str,
                      min_speakers: Optional[int] = None,
                      max_speakers: Optional[int] = None) -> Pipeline:
    """
    Speaker Diarization Pipeline - PyAnnote 3.1.1 Uyumlu
    """
    logger.info("Diarization pipeline yÃ¼kleniyor (PyAnnote 3.1.1)...")

    if min_speakers:
        logger.info(f"Minimum konuÅŸmacÄ± sayÄ±sÄ±: {min_speakers}")
    if max_speakers:
        logger.info(f"Maksimum konuÅŸmacÄ± sayÄ±sÄ±: {max_speakers}")

    try:
        from pyannote.audio import Pipeline

        pipe = Pipeline.from_pretrained(
            "pyannote/speaker-diarization-3.1",
            use_auth_token=hf_token
        )

        logger.info("âœ“ Diarization pipeline yÃ¼klendi")

        # PyAnnote 3.x'te instantiate() boÅŸ dict alÄ±yor
        pipe.instantiate({})

        # min/max speakers iÃ§in wrapper
        if min_speakers is not None or max_speakers is not None:
            class ParameterizedDiarization:
                def __init__(self, pipeline, min_spk, max_spk):
                    self.pipeline = pipeline
                    self.min_speakers = min_spk
                    self.max_speakers = max_spk

                def __call__(self, audio_file, **kwargs):
                    if self.min_speakers is not None:
                        kwargs['min_speakers'] = self.min_speakers
                    if self.max_speakers is not None:
                        kwargs['max_speakers'] = self.max_speakers
                    return self.pipeline(audio_file, **kwargs)

            logger.info(f"KonuÅŸmacÄ± limitleri ayarlandÄ±")
            return ParameterizedDiarization(pipe, min_speakers, max_speakers)

        return pipe

    except Exception as e:
        logger.error(f"Diarization pipeline yÃ¼klenemedi: {e}")
        raise RuntimeError(f"Diarization baÅŸlatÄ±lamadÄ±: {e}")

# ========================= KONUÅMACI ATAMA LOJÄ°ÄÄ° =========================

# KonuÅŸmacÄ± atama parametreleri (fine-tuning iÃ§in)
SMOOTH_WIN = 0.05      # 50ms pencere - Ã§ok hÄ±zlÄ± konuÅŸmacÄ± deÄŸiÅŸimlerini yumuÅŸatÄ±r
STICKY_RATIO = 0.5     # Ã–nceki konuÅŸmacÄ±ya yapÄ±ÅŸma - gÃ¼rÃ¼ltÃ¼yÃ¼ azaltÄ±r
LOCAL_TURN_BIAS = 0.6  # KÄ±sa konuÅŸmalara Ã¶ncelik - kesintileri yakalar

def assign_speaker_midwin(diar: Annotation,
                          word_seg: Segment,
                          prev_spk: Optional[str],
                          is_overlap: bool) -> Tuple[str, float]:
    """
    Kelime segmentine en uygun konuÅŸmacÄ±yÄ± ata

    NASIL Ã‡ALIÅIR?
    1. Kelimenin orta noktasÄ± etrafÄ±nda kÃ¼Ã§Ã¼k bir pencere aÃ§
    2. Bu pencerede en Ã§ok konuÅŸan kiÅŸiyi bul
    3. Ã‡akÄ±ÅŸma varsa Ã¶zel stratejiler uygula
    4. GÃ¼ven skoru hesapla

    STRATEJÄ°LER:
    - Normal durumda: En Ã§ok konuÅŸan kazanÄ±r
    - Ã‡akÄ±ÅŸmada: KÄ±sa/keskin konuÅŸmalara Ã¶ncelik
    - Belirsizlikte: Ã–nceki konuÅŸmacÄ±ya yapÄ±ÅŸ
    """
    # Kelimenin orta noktasÄ±
    tmid = (word_seg.start + word_seg.end) / 2

    # Analiz penceresi
    win = Segment(max(0.0, tmid - SMOOTH_WIN), tmid + SMOOTH_WIN)

    logger.debug(f"Kelime [{format_time(word_seg.start)}-{format_time(word_seg.end)}] "
                 f"iÃ§in konuÅŸmacÄ± atanÄ±yor")
    logger.debug(f"  Analiz penceresi: [{format_time(win.start)}-{format_time(win.end)}]")

    # Penceredeki her konuÅŸmacÄ±nÄ±n konuÅŸma sÃ¼resi
    scores = defaultdict(float)
    total = 0.0
    active_at_mid = []  # Orta noktada aktif konuÅŸmacÄ±lar

    for turn, _, label in diar.itertracks(yield_label=True):
        # Pencere ile kesiÅŸim
        inter = turn & win
        if inter is not None:
            duration = inter.duration
            scores[label] += duration
            total += duration
            logger.debug(f"    {label}: {duration:.3f}s")

        # Orta noktada aktif mi?
        if turn.start <= tmid < turn.end:
            active_at_mid.append((turn, label))

    # HiÃ§ skor yoksa (nadir durum)
    if not scores:
        logger.warning("Pencerede konuÅŸmacÄ± bulunamadÄ±, tam kesiÅŸime bakÄ±lÄ±yor")

        best_label = "SPEAKER_00"
        best_duration = 0.0

        for turn, _, label in diar.itertracks(yield_label=True):
            inter = turn & word_seg
            if inter is not None and inter.duration > best_duration:
                best_duration = inter.duration
                best_label = label

        confidence = min(1.0, best_duration / max(1e-6, word_seg.duration))
        logger.debug(f"  SonuÃ§: {best_label} (gÃ¼ven: {confidence:.2%})")
        return best_label, confidence

    # Ã‡AKIÅMA STRATEJÄ°SÄ°
    if is_overlap and len(active_at_mid) >= 2:
        logger.debug("  âš  Ã‡akÄ±ÅŸma tespit edildi, Ã¶zel strateji uygulanÄ±yor")

        # KonuÅŸmalarÄ± sÃ¼relerine gÃ¶re sÄ±rala
        active_at_mid.sort(key=lambda x: x[0].duration)
        short_turn, short_label = active_at_mid[0]
        long_turn, _ = active_at_mid[-1]

        # KÄ±sa konuÅŸma muhtemelen kesinti/mÃ¼dahale
        if short_turn.duration <= LOCAL_TURN_BIAS * long_turn.duration:
            confidence = min(1.0, scores.get(short_label, 0) / max(total, 1e-6))
            logger.debug(f"  KÄ±sa konuÅŸmaya Ã¶ncelik: {short_label} "
                         f"({short_turn.duration:.2f}s < {LOCAL_TURN_BIAS}*{long_turn.duration:.2f}s)")
            return short_label, confidence

    # NORMAL DURUM: En yÃ¼ksek skoru seÃ§
    candidate = max(scores.items(), key=lambda kv: kv[1])[0]
    confidence = min(1.0, scores[candidate] / max(total, 1e-6))

    logger.debug(f"  En yÃ¼ksek skor: {candidate} ({scores[candidate]:.3f}s / {total:.3f}s)")

    # YAPIÅTIRMA STRATEJÄ°SÄ° (smoothing)
    if is_overlap and prev_spk and candidate != prev_spk:
        prev_score = scores.get(prev_spk, 0.0)
        if scores[candidate] < STICKY_RATIO * prev_score:
            logger.debug(f"  Ã–nceki konuÅŸmacÄ±ya yapÄ±ÅŸÄ±lÄ±yor: {prev_spk} "
                         f"({scores[candidate]:.3f} < {STICKY_RATIO}*{prev_score:.3f})")
            candidate = prev_spk

    logger.debug(f"  âœ“ SonuÃ§: {candidate} (gÃ¼ven: {confidence:.2%})")
    return candidate, confidence

# ========================= ASR (KONUÅMA TANIMA) =========================

def transcribe_words(asr: WhisperModel,
                     audio_path: str,
                     lang: Optional[str]) -> List[Dict]:
    """
    Ses dosyasÄ±nÄ± metne Ã§evir ve kelime zaman damgalarÄ±nÄ± al

    WHISPER NEDÄ°R?
    OpenAI'Ä±n geliÅŸtirdiÄŸi, 680.000 saat ses verisiyle eÄŸitilmiÅŸ
    Ã§ok dilli konuÅŸma tanÄ±ma modeli. 100+ dili destekler.

    KELÄ°ME ZAMAN DAMGALARI:
    Her kelimenin tam olarak ne zaman sÃ¶ylendiÄŸini milisaniye
    hassasiyetinde tespit eder. Bu, konuÅŸmacÄ± atamasÄ± iÃ§in kritik.
    """
    # Model bilgisini gÃ¼venli ÅŸekilde al
    # faster-whisper'da model boyutu farklÄ± saklanÄ±yor
    model_info = "Whisper Model"  # VarsayÄ±lan
    try:
        # FarklÄ± olasÄ± attribute isimlerini dene
        if hasattr(asr, 'model_size'):
            model_info = asr.model_size
        elif hasattr(asr, 'model'):
            model_info = str(asr.model)
        else:
            # Model bilgisi bulunamazsa, sadece "Whisper" yaz
            model_info = "Whisper"
    except:
        pass

    logger.info(f"Transkripsiyon baÅŸlÄ±yor... (Model: {model_info})")
    if lang:
        logger.info(f"Dil: {lang}")

    start_time = datetime.now()

    # Transkripsiyon parametreleri
    segments, info = asr.transcribe(
        audio_path,
        task="transcribe",           # "translate" deÄŸil, orijinal dilde tut
        vad_filter=False,            # VAD'yi kendimiz yapÄ±yoruz
        word_timestamps=True,        # âš  KRÄ°TÄ°K: Kelime zamanlamalarÄ±
        beam_size=10,                # Daha yÃ¼ksek = daha doÄŸru ama yavaÅŸ
        temperature=0.0,             # 0 = deterministik (tutarlÄ± sonuÃ§lar)
        language=lang                # Dil tespitini atla, hÄ±zlandÄ±r
    )

    # Tespit edilen dil bilgisini kontrol et
    if hasattr(info, 'language') and info.language:
        logger.info(f"Tespit edilen dil: {info.language}")

    # Kelimeleri topla
    words = []
    total_segments = 0
    skipped_words = 0

    for seg in segments:
        total_segments += 1

        if not seg.words:
            logger.debug(f"Segment {total_segments}: Kelime yok, atlanÄ±yor")
            continue

        logger.debug(f"Segment {total_segments}: {len(seg.words)} kelime")

        for word in seg.words:
            # Zaman damgasÄ± olmayan kelimeleri atla
            if word.start is None or word.end is None:
                skipped_words += 1
                logger.debug(f"  âš  Kelime atlandÄ± (zaman yok): '{word.word}'")
                continue

            word_dict = {
                "word": word.word.strip(),
                "start": float(word.start),
                "end": float(word.end),
                "confidence": float(getattr(word, "probability", 0.9))
            }

            words.append(word_dict)

            # Ä°lk birkaÃ§ kelimeyi logla (debug modunda)
            if len(words) <= 5 and logger.level <= logging.DEBUG:
                logger.debug(f"  Kelime {len(words)}: '{word_dict['word']}' "
                             f"[{format_time(word_dict['start'])}-{format_time(word_dict['end'])}] "
                             f"(gÃ¼ven: {word_dict['confidence']:.2%})")

    # Ä°statistikler
    elapsed = (datetime.now() - start_time).total_seconds()
    logger.info(f"âœ“ Transkripsiyon tamamlandÄ±:")
    logger.info(f"  SÃ¼re: {elapsed:.1f}s")
    logger.info(f"  Segment: {total_segments}")
    logger.info(f"  Kelime: {len(words)}")
    if skipped_words > 0:
        logger.warning(f"  Atlanan: {skipped_words} kelime (zaman damgasÄ± yok)")

    return words



def create_output_byspeaker(debug_dir: str, segments: List[Dict],
                            speakers: List[str]) -> str:
    """
    Segmentleri konuÅŸmacÄ±lara gÃ¶re organize et ve ayrÄ± bir dosya oluÅŸtur

    Bu fonksiyon, ana Ã§Ä±ktÄ±daki segmentleri alÄ±r ve her konuÅŸmacÄ±nÄ±n
    ne dediÄŸini ayrÄ± ayrÄ± gruplar. Kelime kelime deÄŸil, anlamlÄ±
    cÃ¼mle/segment halinde organize eder.

    Args:
        debug_dir: Debug dosyalarÄ±nÄ±n bulunduÄŸu klasÃ¶r
        segments: Ana programdan gelen konuÅŸma segmentleri (text iÃ§eren)
        speakers: Tespit edilen konuÅŸmacÄ± listesi

    Returns:
        OluÅŸturulan dosyanÄ±n yolu
    """
    output_path = os.path.join(debug_dir, "output_byspeaker.json")

    # Segmentleri konuÅŸmacÄ±lara gÃ¶re grupla
    segments_by_speaker = defaultdict(list)

    for segment in segments:
        speaker = segment["speaker"]
        # Her segmenti olduÄŸu gibi ekle (text dahil)
        segments_by_speaker[speaker].append({
            "id": segment["id"],
            "start": segment["start"],
            "end": segment["end"],
            "text": segment["text"],  # BirleÅŸtirilmiÅŸ metin
            "duration": segment["duration"],
            "word_count": segment["word_count"]
        })

    # Her konuÅŸmacÄ± iÃ§in segmentleri zaman sÄ±rasÄ±na gÃ¶re sÄ±rala
    for speaker in segments_by_speaker:
        segments_by_speaker[speaker].sort(key=lambda x: x["start"])

    # Ã‡Ä±ktÄ± formatÄ±nÄ± oluÅŸtur
    output_data = {
        "description": "KonuÅŸmacÄ±lara gÃ¶re organize edilmiÅŸ segmentler",
        "creation_time": datetime.now().isoformat(),
        "speakers": speakers,
        "total_segments": len(segments),
        "segments_by_speaker": {}
    }

    # Her konuÅŸmacÄ± iÃ§in detaylÄ± bilgi oluÅŸtur
    for speaker in speakers:
        speaker_segments = segments_by_speaker.get(speaker, [])

        if speaker_segments:
            # Ä°statistikler
            total_duration = sum(seg["duration"] for seg in speaker_segments)
            total_words = sum(seg["word_count"] for seg in speaker_segments)
            first_time = speaker_segments[0]["start"]
            last_time = speaker_segments[-1]["end"]

            # TÃ¼m metinleri birleÅŸtir (opsiyonel - tam transkript iÃ§in)
            full_text = " ".join(seg["text"] for seg in speaker_segments)

        else:
            total_duration = 0
            total_words = 0
            first_time = None
            last_time = None
            full_text = ""

        output_data["segments_by_speaker"][speaker] = {
            "segment_count": len(speaker_segments),
            "total_duration": round3(total_duration),
            "total_words": total_words,
            "first_time": round3(first_time) if first_time is not None else None,
            "last_time": round3(last_time) if last_time is not None else None,
            "segments": speaker_segments,  # Text iÃ§eren segmentler
            "full_text": full_text  # TÃ¼m konuÅŸmalarÄ±n birleÅŸimi
        }

    # Genel istatistikler
    total_duration_all = sum(
        data["total_duration"]
        for data in output_data["segments_by_speaker"].values()
    )

    output_data["statistics"] = {}
    for speaker in speakers:
        speaker_data = output_data["segments_by_speaker"][speaker]
        output_data["statistics"][speaker] = {
            "segment_percentage": round(
                100 * speaker_data["segment_count"] / max(len(segments), 1), 2
            ),
            "duration_percentage": round(
                100 * speaker_data["total_duration"] / max(total_duration_all, 1), 2
            ),
            "word_percentage": round(
                100 * speaker_data["total_words"] /
                max(sum(s["total_words"] for s in output_data["segments_by_speaker"].values()), 1), 2
            )
        }

    # DosyayÄ± kaydet
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)

    logger.info(f"âœ“ KonuÅŸmacÄ± bazlÄ± Ã§Ä±ktÄ± oluÅŸturuldu: {output_path}")

    # Ä°statistikleri logla
    logger.info("KonuÅŸmacÄ± segment daÄŸÄ±lÄ±mÄ±:")
    for speaker in speakers:
        seg_count = output_data["segments_by_speaker"][speaker]["segment_count"]
        duration = output_data["segments_by_speaker"][speaker]["total_duration"]
        percentage = output_data["statistics"][speaker]["duration_percentage"]
        logger.info(f"  {speaker}: {seg_count} segment, {duration:.1f}s ({percentage}%)")

    return output_path




# ========================= SEGMENT BÄ°RLEÅTÄ°RME =========================

def merge_words_into_segments(tagged_words: List[Dict],
                              max_gap: float = 0.6,
                              max_len: float = 12.0) -> List[Dict]:
    """
    Kelimeleri anlamlÄ± cÃ¼mle segmentlerine birleÅŸtir

    NEDEN GEREKLÄ°?
    Kelime kelime Ã§Ä±ktÄ± okunmasÄ± zor. Ä°nsanlar cÃ¼mleler halinde
    konuÅŸur. Bu fonksiyon kelimeleri doÄŸal cÃ¼mle yapÄ±larÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.

    STRATEJÄ°:
    - AynÄ± konuÅŸmacÄ±nÄ±n ardÄ±ÅŸÄ±k kelimeleri birleÅŸtir
    - Uzun suskunlukta bÃ¶l (max_gap)
    - Ã‡ok uzun segmentleri bÃ¶l (max_len)
    """
    if not tagged_words:
        logger.warning("BirleÅŸtirilecek kelime yok")
        return []

    logger.info(f"Kelimeler cÃ¼mlelere birleÅŸtiriliyor... "
                f"({len(tagged_words)} kelime)")
    logger.debug(f"Parametreler: max_gap={max_gap}s, max_len={max_len}s")

    segments = []
    current = None

    for i, word in enumerate(tagged_words):
        if current is None:
            # Ä°lk segment
            current = {
                "start": word["start"],
                "end": word["end"],
                "speaker": word["speaker"],
                "words": [word["word"]],
                "overlap_count": 1 if word.get("is_overlap") else 0
            }
            logger.debug(f"Yeni segment baÅŸladÄ±: {word['speaker']} @ {format_time(word['start'])}")
            continue

        # BirleÅŸtirme kriterleri
        same_speaker = (word["speaker"] == current["speaker"])
        gap = word["start"] - current["end"]
        total_length = word["end"] - current["start"]

        gap_ok = gap <= max_gap
        length_ok = total_length <= max_len

        if logger.level <= logging.DEBUG and i < 10:  # Ä°lk 10 kelime iÃ§in detay
            logger.debug(f"  Kelime {i}: '{word['word']}' - "
                         f"AynÄ± konuÅŸmacÄ±: {same_speaker}, "
                         f"BoÅŸluk: {gap:.2f}s, "
                         f"Toplam: {total_length:.2f}s")

        if same_speaker and gap_ok and length_ok:
            # Mevcut segmente ekle
            current["end"] = word["end"]
            current["words"].append(word["word"])
            if word.get("is_overlap"):
                current["overlap_count"] += 1
        else:
            # Yeni segment baÅŸlat
            segments.append(current)

            if not same_speaker:
                logger.debug(f"KonuÅŸmacÄ± deÄŸiÅŸti: {current['speaker']} â†’ {word['speaker']}")
            elif not gap_ok:
                logger.debug(f"Uzun boÅŸluk: {gap:.2f}s > {max_gap}s")
            elif not length_ok:
                logger.debug(f"Segment Ã§ok uzun: {total_length:.2f}s > {max_len}s")

            current = {
                "start": word["start"],
                "end": word["end"],
                "speaker": word["speaker"],
                "words": [word["word"]],
                "overlap_count": 1 if word.get("is_overlap") else 0
            }

    # Son segmenti ekle
    if current is not None:
        segments.append(current)

    logger.info(f"âœ“ {len(segments)} segment oluÅŸturuldu")

    # Formatla ve istatistikleri hesapla
    formatted = []
    speaker_segments = defaultdict(int)

    for i, s in enumerate(segments):
        overlap_ratio = s["overlap_count"] / len(s["words"])

        formatted_seg = {
            "id": i,
            "start": round3(s["start"]),
            "end": round3(s["end"]),
            "text": " ".join(s["words"]).strip(),
            "speaker": s["speaker"],
            "duration": round3(s["end"] - s["start"]),
            "word_count": len(s["words"]),
            "overlap_ratio": round3(overlap_ratio)
        }

        formatted.append(formatted_seg)
        speaker_segments[s["speaker"]] += 1

        # Ä°lk birkaÃ§ segmenti logla
        if i < 3 and logger.level <= logging.DEBUG:
            logger.debug(f"Segment {i}: {s['speaker']} "
                         f"[{format_time(s['start'])}-{format_time(s['end'])}] "
                         f"({len(s['words'])} kelime): "
                         f"'{' '.join(s['words'][:5])}...'")

    # Segment istatistikleri
    logger.info("Segment daÄŸÄ±lÄ±mÄ±:")
    for speaker, count in sorted(speaker_segments.items()):
        logger.info(f"  {speaker}: {count} segment")

    return formatted

def filter_tiny_overlaps(overlap_tl: Timeline,
                         min_duration: float = 0.5) -> Timeline:
    """
    Ã‡ok kÄ±sa Ã§akÄ±ÅŸma bÃ¶lgelerini filtrele

    NEDEN?
    Ã‡ok kÄ±sa Ã§akÄ±ÅŸmalar genelde yanlÄ±ÅŸ algÄ±lamadÄ±r.
    0.5 saniyeden kÄ±sa Ã§akÄ±ÅŸmalar muhtemelen gÃ¼rÃ¼ltÃ¼.
    """
    logger.debug(f"KÄ±sa Ã§akÄ±ÅŸmalar filtreleniyor (min: {min_duration}s)")

    original_count = len(overlap_tl)
    filtered = []
    removed = []

    for seg in overlap_tl:
        if seg.duration >= min_duration:
            filtered.append(seg)
        else:
            removed.append(seg)

    if removed:
        logger.info(f"Filtrelenen Ã§akÄ±ÅŸmalar: {len(removed)}/{original_count}")
        for r in removed[:5]:  # Ä°lk 5 tanesini gÃ¶ster
            logger.debug(f"  KaldÄ±rÄ±ldÄ±: [{format_time(r.start)}-{format_time(r.end)}] "
                         f"({r.duration:.3f}s)")

    return Timeline(filtered).support() if filtered else Timeline()

def post_merge_tiny_segments(segments: List[Dict],
                             min_duration: float = 2.0,
                             max_gap: float = 1.5) -> List[Dict]:
    """
    Ã‡ok kÄ±sa segmentleri komÅŸularÄ±yla birleÅŸtir

    NEDEN?
    KÄ±sa segmentler (< 2s) genelde kesik cÃ¼mlelerdir:
    - "Evet." (0.5s)
    - "Hmm..." (0.3s)
    - "Peki." (0.4s)

    BunlarÄ± bir sonraki segmentle birleÅŸtirmek daha doÄŸal.
    """
    if not segments:
        return segments

    logger.info(f"KÄ±sa segmentler birleÅŸtiriliyor (min: {min_duration}s)...")

    merged = []
    i = 0
    merge_count = 0

    while i < len(segments):
        seg = segments[i]
        duration = seg["end"] - seg["start"]

        # KÄ±sa segment ve sonraki segment varsa
        if duration < min_duration and i + 1 < len(segments):
            next_seg = segments[i + 1]
            gap = next_seg["start"] - seg["end"]

            # BirleÅŸtirme kriterleri
            same_speaker = (seg["speaker"] == next_seg["speaker"])
            gap_ok = gap <= max_gap

            if same_speaker and gap_ok:
                # BirleÅŸtir
                merged_seg = {
                    "id": len(merged),
                    "start": seg["start"],
                    "end": next_seg["end"],
                    "text": seg["text"] + " " + next_seg["text"],
                    "speaker": seg["speaker"],
                    "duration": round3(next_seg["end"] - seg["start"]),
                    "word_count": seg.get("word_count", 0) + next_seg.get("word_count", 0)
                }

                merged.append(merged_seg)
                merge_count += 1

                logger.debug(f"BirleÅŸtirildi: Segment {seg['id']} + {next_seg['id']} "
                             f"({duration:.1f}s + {next_seg['end']-next_seg['start']:.1f}s)")

                i += 2  # Ä°ki segmenti atla
                continue

        # BirleÅŸtirme yapÄ±lamadÄ±
        seg_copy = seg.copy()
        seg_copy["id"] = len(merged)
        merged.append(seg_copy)
        i += 1

    if merge_count > 0:
        logger.info(f"âœ“ {merge_count} segment birleÅŸtirildi "
                    f"({len(segments)} â†’ {len(merged)} segment)")

    return merged
def create_output_byspeaker_from_tagged_words(debug_dir: str,
                                              tagged_words: List[Dict],
                                              speakers: List[str],
                                              max_gap: float = 1.5,
                                              max_len: float = 30.0) -> str:
    """
    Tagged words'den direkt konuÅŸmacÄ± bazlÄ± Ã§Ä±ktÄ± oluÅŸtur

    Args:
        debug_dir: Debug dosyalarÄ±nÄ±n bulunduÄŸu klasÃ¶r
        tagged_words: KonuÅŸmacÄ± atamalÄ± kelimeler
        speakers: Tespit edilen konuÅŸmacÄ± listesi
        max_gap: Segment birleÅŸtirme iÃ§in maksimum boÅŸluk (saniye)
        max_len: Maksimum segment uzunluÄŸu (saniye)

    Returns:
        OluÅŸturulan dosyanÄ±n yolu
    """
    output_path = os.path.join(debug_dir, "output_byspeaker.json")

    # Her konuÅŸmacÄ± iÃ§in kelimeleri segmentlere dÃ¶nÃ¼ÅŸtÃ¼r
    segments_by_speaker = {}

    for speaker in speakers:
        # Bu konuÅŸmacÄ±ya ait kelimeleri filtrele
        speaker_words = [w for w in tagged_words if w["speaker"] == speaker]

        if not speaker_words:
            segments_by_speaker[speaker] = {"segments": []}
            continue

        # Kelimeleri segmentlere birleÅŸtir
        segments = []
        current_segment = None
        segment_id = 0

        for word in speaker_words:
            if current_segment is None:
                # Ä°lk segment
                current_segment = {
                    "id": segment_id,
                    "start": round3(word["start"]),
                    "end": round3(word["end"]),
                    "words": [word["word"]],
                    "speaker": speaker
                }
            else:
                # BirleÅŸtirme kriterleri
                gap = word["start"] - current_segment["end"]
                total_length = word["end"] - current_segment["start"]

                if gap <= max_gap and total_length <= max_len:
                    # Mevcut segmente ekle
                    current_segment["end"] = round3(word["end"])
                    current_segment["words"].append(word["word"])
                else:
                    # Yeni segment baÅŸlat
                    # Ã–nce mevcut segmenti kaydet
                    current_segment["text"] = " ".join(current_segment["words"])
                    current_segment["duration"] = round3(
                        current_segment["end"] - current_segment["start"]
                    )
                    current_segment["word_count"] = len(current_segment["words"])
                    del current_segment["words"]  # words alanÄ±nÄ± kaldÄ±r
                    segments.append(current_segment)

                    segment_id += 1
                    current_segment = {
                        "id": segment_id,
                        "start": round3(word["start"]),
                        "end": round3(word["end"]),
                        "words": [word["word"]],
                        "speaker": speaker
                    }

        # Son segmenti ekle
        if current_segment:
            current_segment["text"] = " ".join(current_segment["words"])
            current_segment["duration"] = round3(
                current_segment["end"] - current_segment["start"]
            )
            current_segment["word_count"] = len(current_segment["words"])
            del current_segment["words"]  # words alanÄ±nÄ± kaldÄ±r
            del current_segment["speaker"]  # speaker alanÄ±nÄ± kaldÄ±r (zaten Ã¼st seviyede var)
            segments.append(current_segment)

        # KonuÅŸmacÄ±ya ait segmentleri kaydet
        segments_by_speaker[speaker] = {
            "segments": segments
        }

    # DosyayÄ± kaydet
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(segments_by_speaker, f, ensure_ascii=False, indent=2)

    logger.info(f"âœ“ KonuÅŸmacÄ± bazlÄ± Ã§Ä±ktÄ± oluÅŸturuldu: {output_path}")

    # Ä°statistikleri logla
    logger.info("KonuÅŸmacÄ± segment daÄŸÄ±lÄ±mÄ±:")
    for speaker in speakers:
        seg_count = len(segments_by_speaker[speaker]["segments"])
        if seg_count > 0:
            total_duration = sum(s["duration"] for s in segments_by_speaker[speaker]["segments"])
            total_words = sum(s["word_count"] for s in segments_by_speaker[speaker]["segments"])
            logger.info(f"  {speaker}: {seg_count} segment, {total_duration:.1f}s, {total_words} kelime")

    return output_path


def process_dialog(input_json, out_json_path):
    http_client = httpx.Client(transport=transport)

    client = anthropic.Anthropic(
            api_key=os.getenv("ANTHROPIC_API_KEY"),
            http_client=http_client
        )
        # Diarization ve input parametrelerini ekledik
    message = client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=128000,
        temperature=1,
        system="Verilen ardÄ±ÅŸÄ±k cÃ¼mleleri mantÄ±ksal sÄ±raya gÃ¶re dÃ¼zenle ve mantÄ±klÄ± dialog olacak sekilde aÅŸaÄŸÄ±daki kriterlere uygun bir JSON Ã§Ä±ktÄ±sÄ± oluÅŸtur:\n\nGereksinimler:\n1. CÃ¼mleleri mantÄ±ksal ve dilbilgisi aÃ§Ä±sÄ±ndan doÄŸru bir sÄ±raya koy\n2. Her bir cÃ¼mlenin yanÄ±na ISO 8601 formatÄ±nda bir zaman damgasÄ± ekle\n3. JSON formatÄ±nda Ã§Ä±ktÄ± ver\n4. Her cÃ¼mlenin benzersiz bir ID'si olmalÄ±\n5. CÃ¼mlelerin sÄ±ralamasÄ±nÄ± ve mantÄ±ksal akÄ±ÅŸÄ±nÄ± kontrol et\n6. en Ã¶neli adim {{SEGMENT_INPUT_JSON}} uygun olmali\nJSON Åablonu:\n{\n \"sentences\": [\n {\n \"id\": \"unique_id_1\",\n \"text\": \"DÃ¼zenlenmiÅŸ cÃ¼mle\",\n \"start\": 0.0,\n \"end\": 3.64,\n \"duration\": 13.7,\n \"word_count\": 52,\n \"speaker\": \"SPEAKER_00\",\n },\n ...\n ]\n}",
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "\n\n\nBeklenen Ã‡Ä±ktÄ±: MantÄ±ksal sÄ±ralanmÄ±ÅŸ, zaman damgalÄ± JSON\n\n\nGirdi: \n{{INPUT_JSON}}\n{{SEGMENT_INPUT_JSON}}"
                    }
                ]
            }
        ],
        thinking={
            "type": "enabled",
            "budget_tokens": 51200
        }
    )

    # Ã‡Ä±ktÄ±yÄ± JSON dosyasÄ±na kaydet
    try:
        processed_dialog = json.loads(message.content[0].text)

        # Diarization bilgilerini ekle
        diarization_info = {
            "speakers": ["SPEAKER_00", "SPEAKER_01"],
            "total_speakers": 2,
            "language": "tr",
            "processing_time": 0.5  # saniye cinsinden
        }

        processed_dialog["diarization"] = diarization_info

        # Ã‡Ä±ktÄ±yÄ± dosyaya yaz
        with open(out_json_path, 'w', encoding='utf-8') as f:
            json.dump(processed_dialog, f, ensure_ascii=False, indent=2)

        print(f"Ä°ÅŸlenen dialog {out_json_path} dosyasÄ±na kaydedildi.")
        return processed_dialog

    except json.JSONDecodeError as e:
        print(f"JSON Decode HatasÄ±: {e}")
        return None
    except Exception as e:
        print(f"Bir hata oluÅŸtu: {e}")
        return None


# ========================= ANA PROGRAM =========================

def main():

    """
    Ana program akÄ±ÅŸÄ±:
    1. Parametreleri al
    2. Ses dosyasÄ±nÄ± hazÄ±rla
    3. Modelleri yÃ¼kle
    4. Analizleri yap (VAD, OSD, Diarization)
    5. Transkripsiyon yap
    6. KonuÅŸmacÄ±larÄ± ata
    7. Segmentleri oluÅŸtur
    8. SonuÃ§larÄ± kaydet
    """
    parser = argparse.ArgumentParser(
        description="ğŸ™ï¸ Ses DosyasÄ± Diarizasyon ve Transkripsiyon Sistemi",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ã–rnek kullanÄ±m:
  python diarize.py --input meeting.mp4 --output result.json --hf-token YOUR_TOKEN
  
Debug modu:
  python diarize.py --input audio.wav --output out.json --hf-token TOKEN --debug DEBUG --log-file debug.log
        """
    )

    # Temel parametreler
    parser.add_argument("--input", required=True,
                        help="Girdi ses dosyasÄ± (MP4/MP3/WAV)")
    parser.add_argument("--output", required=True,
                        help="Ã‡Ä±ktÄ± JSON dosyasÄ±")
    parser.add_argument("--hf-token",
                        default=os.environ.get("HF_TOKEN"),
                        help="HuggingFace API token (veya $HF_TOKEN)")

    # Debug parametreleri
    parser.add_argument("--debug", default="INFO",
                        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
                        help="Debug seviyesi")
    parser.add_argument("--log-file", default=None,
                        help="Log dosyasÄ± (opsiyonel)")
    parser.add_argument("--dump-debug", default=None,
                        help="Ara sonuÃ§larÄ± kaydet (klasÃ¶r yolu)")

    # ASR parametreleri
    parser.add_argument("--asr-model", default="large-v3",
                        choices=["tiny", "base", "small", "medium", "large", "large-v2", "large-v3"],
                        help="Whisper model boyutu")
    parser.add_argument("--asr-device", default="auto",
                        help="Ä°ÅŸlemci (cpu/cuda/auto)")
    parser.add_argument("--asr-compute-type", default="auto",
                        help="Hesaplama tipi (int8/float16/auto)")
    parser.add_argument("--language", default=None,
                        help="Transkripsiyon dili (tr, en, vb.)")

    # Diarization parametreleri
    parser.add_argument("--min-speakers", type=int, default=None,
                        help="Minimum konuÅŸmacÄ± sayÄ±sÄ±")
    parser.add_argument("--max-speakers", type=int, default=None,
                        help="Maksimum konuÅŸmacÄ± sayÄ±sÄ±")

    # Filtreleme parametreleri
    parser.add_argument("--require-vad", action="store_true",
                        help="Sadece VAD tespit edilen bÃ¶lgeleri kullan")
    parser.add_argument("--vad-coverage", type=float, default=0.6,
                        help="Minimum VAD kapsama oranÄ± (0-1)")

    args = parser.parse_args()

    # Logger kurulumu
    global logger
    logger = setup_logger(args.debug, args.log_file)

    # BaÅŸlangÄ±Ã§
    logger.info("="*60)
    logger.info("ğŸ™ï¸  SES DOSYASI DÄ°ARÄ°ZASYON VE TRANSKRÄ°PSÄ°YON")
    logger.info("="*60)
    logger.info(f"Girdi: {args.input}")
    logger.info(f"Ã‡Ä±ktÄ±: {args.output}")
    logger.info(f"Debug seviyesi: {args.debug}")

    # Token kontrolÃ¼
    if not args.hf_token:
        logger.error("HuggingFace token gerekli! --hf-token veya $HF_TOKEN")
        sys.exit(1)

    try:
        # ============ AÅAMA 1: SES HAZIRLAMA ============
        logger.info("\n" + "="*40)
        logger.info("AÅAMA 1: SES DOSYASI HAZIRLAMA")
        logger.info("="*40)

        wav_path = ffmpeg_to_wav_mono16k(args.input)

        # ============ AÅAMA 2: MODEL YÃœKLEME ============
        logger.info("\n" + "="*40)
        logger.info("AÅAMA 2: MODELLERÄ° YÃœKLEME")
        logger.info("="*40)

        vad = build_vad(args.hf_token)
        osd = build_osd(args.hf_token)
        diar = build_diarization(args.hf_token,
                                 args.min_speakers,
                                 args.max_speakers)

        logger.info(f"\nWhisper modeli yÃ¼kleniyor: {args.asr_model}")
        asr = WhisperModel(args.asr_model,
                           device=args.asr_device,
                           compute_type=args.asr_compute_type)
        logger.info("âœ“ TÃ¼m modeller hazÄ±r")

        # ============ AÅAMA 3: SES ANALÄ°ZÄ° ============
        logger.info("\n" + "="*40)
        logger.info("AÅAMA 3: SES ANALÄ°ZÄ°")
        logger.info("="*40)

        # 3.1 Voice Activity Detection
        logger.info("\n--- VAD (KonuÅŸma Tespiti) ---")
        vad_ann = vad(wav_path)
        vad_timeline = vad_ann.get_timeline().support()
        log_timeline(vad_timeline, "VAD Sonucu")

        # 3.2 Overlapped Speech Detection
        logger.info("\n--- OSD (Ã‡akÄ±ÅŸma Tespiti) ---")
        osd_ann = osd(wav_path)
        osd_timeline = osd_ann.get_timeline().support()
        log_timeline(osd_timeline, "OSD Sonucu")

        # 3.3 Speaker Diarization
        logger.info("\n--- Diarization (KonuÅŸmacÄ± AyrÄ±mÄ±) ---")
        diar_ann = diar(wav_path)

        # KonuÅŸmacÄ± sayÄ±sÄ±
        speakers = list(diar_ann.labels())
        logger.info(f"Tespit edilen konuÅŸmacÄ± sayÄ±sÄ±: {len(speakers)}")
        logger.info(f"KonuÅŸmacÄ±lar: {', '.join(speakers)}")

        # 3.4 Ã‡akÄ±ÅŸma bÃ¶lgelerini belirle
        logger.info("\n--- Ã‡akÄ±ÅŸma Analizi ---")
        diar_overlap = build_overlap_from_diarization(diar_ann, min_count=2)
        osd_in_vad = intersect_timelines(osd_timeline, vad_timeline)
        final_overlap = intersect_timelines(osd_in_vad, diar_overlap)
        final_overlap = filter_tiny_overlaps(final_overlap, min_duration=0.5)
        log_timeline(final_overlap, "Final Ã‡akÄ±ÅŸma BÃ¶lgeleri")

        # ============ AÅAMA 4: TRANSKRÄ°PSÄ°YON ============
        logger.info("\n" + "="*40)
        logger.info("AÅAMA 4: TRANSKRÄ°PSÄ°YON")
        logger.info("="*40)

        words = transcribe_words(asr, wav_path, args.language)

        # ============ AÅAMA 5: KONUÅMACI ATAMA ============
        logger.info("\n" + "="*40)
        logger.info("AÅAMA 5: KONUÅMACI ATAMA")
        logger.info("="*40)

        prev_speaker = None
        tagged_words = []
        vad_filtered = 0
        overlap_words = 0

        for i, word in enumerate(words):
            seg = Segment(word["start"], word["end"])

            # VAD filtresi
            if args.require_vad:
                coverage = timeline_coverage_ratio(vad_timeline, seg)
                if coverage < args.vad_coverage:
                    vad_filtered += 1
                    logger.debug(f"Kelime {i} VAD filtresine takÄ±ldÄ±: "
                                 f"'{word['word']}' (kapsama: {coverage:.2%})")
                    continue

            # Ã‡akÄ±ÅŸma kontrolÃ¼
            is_overlap = timeline_overlaps(final_overlap, seg)
            if is_overlap:
                overlap_words += 1

            # KonuÅŸmacÄ± ata
            speaker, confidence = assign_speaker_midwin(
                diar_ann, seg, prev_speaker, is_overlap
            )

            prev_speaker = speaker

            tagged_words.append({
                "word": word["word"],
                "start": word["start"],
                "end": word["end"],
                "speaker": speaker,
                "confidence": word["confidence"],
                "speaker_confidence": confidence,
                "is_overlap": is_overlap
            })

            # Ä°lerleme gÃ¶stergesi
            if (i + 1) % 100 == 0:
                logger.info(f"  Ä°ÅŸlenen kelime: {i+1}/{len(words)}")

        logger.info(f"âœ“ KonuÅŸmacÄ± atamasÄ± tamamlandÄ±:")
        logger.info(f"  Toplam kelime: {len(words)}")
        logger.info(f"  Ä°ÅŸlenen: {len(tagged_words)}")
        if vad_filtered > 0:
            logger.info(f"  VAD filtresi: {vad_filtered} kelime")
        if overlap_words > 0:
            logger.info(f"  Ã‡akÄ±ÅŸmada: {overlap_words} kelime")

        # ============ AÅAMA 6: SEGMENT OLUÅTURMA ============
        logger.info("\n" + "="*40)
        logger.info("AÅAMA 6: SEGMENT OLUÅTURMA")
        logger.info("="*40)

        segments = merge_words_into_segments(tagged_words,
                                             max_gap=1.5,
                                             max_len=30.0)

        # KÃ¼Ã§Ã¼k segmentleri birleÅŸtir
        segments = post_merge_tiny_segments(segments,
                                            min_duration=2.0,
                                            max_gap=1.5)

        # ============ AÅAMA 7: Ã‡IKTI KAYDETME ============
        logger.info("\n" + "="*40)
        logger.info("AÅAMA 7: SONUÃ‡LARI KAYDETME")
        logger.info("="*40)

        # Ana Ã§Ä±ktÄ±
        output = {
            "metadata": {
                "input_file": args.input,
                "total_segments": len(segments),
                "speakers": speakers,
                "language": args.language or "auto",
                "model": args.asr_model,
                "processing_date": datetime.now().isoformat()
            },
            "segments": segments
        }

        input_json = diar_ann
        out_json_path = output

        result = process_dialog(input_json, out_json_path)
        with open(args.output, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)

        logger.info(f"âœ“ Ana Ã§Ä±ktÄ± kaydedildi: {args.output}")

        # Debug dosyalarÄ±
        if args.dump_debug:
            logger.info(f"\nDebug dosyalarÄ± kaydediliyor: {args.dump_debug}")
            os.makedirs(args.dump_debug, exist_ok=True)

            debug_files = {
                "vad.json": {
                    "description": "Voice Activity Detection sonuÃ§larÄ±",
                    "segments": timeline_to_dict(vad_timeline)
                },
                "osd.json": {
                    "description": "Overlapped Speech Detection sonuÃ§larÄ±",
                    "segments": timeline_to_dict(osd_timeline)
                },
                "diarization.json": {
                    "description": "Speaker Diarization sonuÃ§larÄ±",
                    "speakers": speakers,
                    "segments": diarization_to_dict(diar_ann)
                },
                "overlap.json": {
                    "description": "Final Ã§akÄ±ÅŸma bÃ¶lgeleri",
                    "segments": timeline_to_dict(final_overlap)
                },
                "words.json": {
                    "description": "Transkribe edilmiÅŸ kelimeler",
                    "total": len(words),
                    "words": words[:100]  # Ä°lk 100 kelime
                },
                "tagged_words.json": {
                    "description": "KonuÅŸmacÄ± atamalÄ± kelimeler",
                    "total": len(tagged_words),
                    "words": tagged_words[:100]  # Ä°lk 100 kelime
                }
            }



            for filename, data in debug_files.items():
                filepath = os.path.join(args.dump_debug, filename)
                with open(filepath, "w", encoding="utf-8") as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
                logger.info(f"  âœ“ {filename}")





        # Temizlik
        try:
            os.remove(wav_path)
            logger.info(f"\nGeÃ§ici dosya silindi: {wav_path}")
        except Exception as e:
            logger.warning(f"GeÃ§ici dosya silinemedi: {e}")

        # ============ Ã–ZET ============
        logger.info("\n" + "="*60)
        logger.info("âœ¨ Ä°ÅLEM BAÅARIYLA TAMAMLANDI!")
        logger.info("="*60)
        logger.info(f"Ã‡Ä±ktÄ± dosyasÄ±: {args.output}")
        logger.info(f"Toplam segment: {len(segments)}")
        logger.info(f"KonuÅŸmacÄ± sayÄ±sÄ±: {len(speakers)}")

        # Segment uzunluk istatistikleri
        if segments:
            durations = [s['duration'] for s in segments if 'duration' in s]
            if durations:
                logger.info(f"Ortalama segment sÃ¼resi: {np.mean(durations):.1f}s")
                logger.info(f"En kÄ±sa segment: {min(durations):.1f}s")
                logger.info(f"En uzun segment: {max(durations):.1f}s")

    except Exception as e:
        logger.error(f"\n{'='*60}")
        logger.error(f"âŒ HATA OLUÅTU!")
        logger.error(f"{'='*60}")
        logger.error(f"{type(e).__name__}: {e}", exc_info=True)
        sys.exit(1)

if __name__ == "__main__":
    main()