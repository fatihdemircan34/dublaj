"""
Speaker Diarization Pipeline with Detailed RTTM Output
Uses pyannote/speaker-diarization-3.1 model
"""

import os
import sys
from pathlib import Path
from pyannote.audio import Pipeline
from pyannote.core import Segment, Annotation
import torch

class SpeakerDiarization:
    def __init__(self, auth_token):
        """
        Initialize the speaker diarization pipeline

        Args:
            auth_token: HuggingFace authentication token
        """
        self.auth_token = auth_token
        self.pipeline = None

    def load_pipeline(self, use_gpu=True):
        """
        Load the pre-trained diarization model

        Args:
            use_gpu: Whether to use GPU if available
        """
        print("Loading pyannote speaker-diarization-3.1 model...")

        # Check for GPU availability
        device = torch.device("cuda" if torch.cuda.is_available() and use_gpu else "cpu")
        print(f"Using device: {device}")

        # Load the pipeline
        self.pipeline = Pipeline.from_pretrained(
            "pyannote/speaker-diarization-3.1",
            use_auth_token=self.auth_token
        )

        # Send pipeline to device
        self.pipeline.to(device)

        print("Model loaded successfully!")
        return self.pipeline

    def process_audio(self, audio_path, num_speakers=None, min_speakers=None, max_speakers=None):
        """
        Process audio file for speaker diarization

        Args:
            audio_path: Path to the audio file
            num_speakers: Exact number of speakers (if known)
            min_speakers: Minimum number of speakers
            max_speakers: Maximum number of speakers

        Returns:
            Diarization annotation object
        """
        if not self.pipeline:
            raise ValueError("Pipeline not loaded. Call load_pipeline() first.")

        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"Audio file not found: {audio_path}")

        print(f"\nProcessing: {audio_path}")
        print("Running diarization... (this may take a while)")

        # Set diarization parameters
        diarization_params = {}
        if num_speakers is not None:
            diarization_params["num_speakers"] = num_speakers
        elif min_speakers is not None or max_speakers is not None:
            diarization_params["min_speakers"] = min_speakers
            diarization_params["max_speakers"] = max_speakers

        # Run diarization
        diarization = self.pipeline(audio_path, **diarization_params)

        # Print summary
        print(f"\nDiarization complete!")
        print(f"Found {len(diarization.labels())} speakers")
        print(f"Total segments: {len(list(diarization.itertracks()))}")

        return diarization

    def write_detailed_rttm(self, diarization, output_path, audio_filename=None):
        """
        Write detailed RTTM format output with additional metadata

        Args:
            diarization: Diarization annotation object
            output_path: Path for output RTTM file
            audio_filename: Name of the audio file for RTTM header
        """
        print(f"\nWriting detailed RTTM to: {output_path}")

        with open(output_path, "w") as rttm_file:
            # Write header comments
            rttm_file.write(f";; Generated by pyannote-audio speaker-diarization-3.1\n")
            if audio_filename:
                rttm_file.write(f";; Source file: {audio_filename}\n")
            rttm_file.write(f";; Number of speakers: {len(diarization.labels())}\n")
            rttm_file.write(f";; Speakers: {', '.join(sorted(diarization.labels()))}\n")
            rttm_file.write(";;\n")

            # Calculate statistics
            speaker_times = {label: 0.0 for label in diarization.labels()}

            # Write RTTM entries and calculate speaker times
            for segment, track, label in diarization.itertracks(yield_label=True):
                # RTTM format: SPEAKER file_id channel start_time duration <NA> <NA> speaker_id <NA> <NA>
                start_time = segment.start
                duration = segment.duration

                # Use audio filename as file_id if provided, otherwise use generic
                file_id = Path(audio_filename).stem if audio_filename else "audio"

                # Write RTTM line
                rttm_line = f"SPEAKER {file_id} 1 {start_time:.3f} {duration:.3f} <NA> <NA> {label} <NA> <NA>\n"
                rttm_file.write(rttm_line)

                # Update speaker time
                speaker_times[label] += duration

            # Write summary statistics as comments at the end
            rttm_file.write("\n;; SUMMARY STATISTICS\n")
            total_time = sum(speaker_times.values())
            for speaker, time in sorted(speaker_times.items()):
                percentage = (time / total_time * 100) if total_time > 0 else 0
                rttm_file.write(f";; {speaker}: {time:.2f}s ({percentage:.1f}%)\n")
            rttm_file.write(f";; Total speaking time: {total_time:.2f}s\n")

        print(f"RTTM file written successfully!")
        return speaker_times

    def print_timeline(self, diarization, max_width=80):
        """
        Print a visual timeline of speaker segments

        Args:
            diarization: Diarization annotation object
            max_width: Maximum width of the timeline display
        """
        print("\n" + "="*max_width)
        print("SPEAKER TIMELINE")
        print("="*max_width)

        # Get all segments
        segments = list(diarization.itertracks(yield_label=True))
        if not segments:
            print("No segments found")
            return

        # Find the total duration
        total_duration = max(seg[0].end for seg in segments)

        # Create timeline for each speaker
        for label in sorted(diarization.labels()):
            print(f"\n{label}:")
            timeline = [' '] * max_width

            # Mark segments for this speaker
            for segment, track, seg_label in segments:
                if seg_label == label:
                    start_pos = int(segment.start / total_duration * max_width)
                    end_pos = int(segment.end / total_duration * max_width)
                    for i in range(start_pos, min(end_pos + 1, max_width)):
                        timeline[i] = 'â–ˆ'

            print(''.join(timeline))

        # Time scale
        print("\n" + "-" * max_width)
        print(f"0s" + " " * (max_width - 10) + f"{total_duration:.1f}s")
        print("="*max_width)


def main():
    # Configuration
    AUTH_TOKEN = "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"
    AUDIO_FILE = "/home/videodubb_voiceprocess_io/PycharmProjects/dublaj/input_6.wav"  # Change this to your audio file path
    OUTPUT_RTTM = "audio_detailed.rttm"

    # Optional: Specify number of speakers if known
    NUM_SPEAKERS = None  # Set to a number if you know the exact count
    MIN_SPEAKERS = None  # Set minimum number of speakers
    MAX_SPEAKERS = None  # Set maximum number of speakers

    try:
        # Initialize diarization
        diarizer = SpeakerDiarization(AUTH_TOKEN)

        # Load the model
        diarizer.load_pipeline(use_gpu=True)  # Set to False if no GPU

        # Process the audio
        diarization = diarizer.process_audio(
            AUDIO_FILE,
            num_speakers=NUM_SPEAKERS,
            min_speakers=MIN_SPEAKERS,
            max_speakers=MAX_SPEAKERS
        )

        # Write detailed RTTM
        speaker_times = diarizer.write_detailed_rttm(
            diarization,
            OUTPUT_RTTM,
            audio_filename=AUDIO_FILE
        )

        # Print visual timeline
        diarizer.print_timeline(diarization)

        # Print summary
        print("\n" + "="*50)
        print("PROCESSING COMPLETE")
        print("="*50)
        print(f"Input audio: {AUDIO_FILE}")
        print(f"Output RTTM: {OUTPUT_RTTM}")
        print(f"Speakers detected: {len(diarization.labels())}")
        print("\nSpeaker breakdown:")
        for speaker, time in sorted(speaker_times.items()):
            print(f"  {speaker}: {time:.2f} seconds")

    except Exception as e:
        print(f"\nError occurred: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    main()